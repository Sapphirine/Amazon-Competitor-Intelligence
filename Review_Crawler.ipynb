{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "880cf625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and processing page http://www.amazon.com/dp/B01ETPUQ6E\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siyuwu/miniforge3/envs/scraper/lib/python3.8/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.amazon.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and processing page http://www.amazon.com/dp/B017HW9DEW\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siyuwu/miniforge3/envs/scraper/lib/python3.8/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.amazon.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and processing page http://www.amazon.com/dp/B00U8KSIOM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siyuwu/miniforge3/envs/scraper/lib/python3.8/site-packages/urllib3/connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.amazon.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "# Written as part of https://www.scrapehero.com/how-to-scrape-amazon-product-reviews-using-python/\n",
    "from lxml import html\n",
    "from json import dump,loads\n",
    "from requests import get\n",
    "import json\n",
    "from re import sub\n",
    "from dateutil import parser as dateparser\n",
    "from time import sleep\n",
    "\n",
    "def ParseReviews(asin):\n",
    "    # This script has only been tested with Amazon.com\n",
    "    amazon_url  = 'http://www.amazon.com/dp/'+asin\n",
    "    # Add some recent user agent to prevent amazon from blocking the request \n",
    "    # Find some chrome user agent strings  here https://udger.com/resources/ua-list/browser-detail?browser=Chrome\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'}\n",
    "    for i in range(5):\n",
    "        response = get(amazon_url, headers = headers, verify=False, timeout=30)\n",
    "        if response.status_code == 404:\n",
    "            return {\"url\": amazon_url, \"error\": \"page not found\"}\n",
    "        if response.status_code != 200:\n",
    "            continue\n",
    "        \n",
    "        # Removing the null bytes from the response.\n",
    "        cleaned_response = response.text.replace('\\x00', '')\n",
    "        \n",
    "        parser = html.fromstring(cleaned_response)\n",
    "        XPATH_AGGREGATE = '//span[@id=\"acrCustomerReviewText\"]'\n",
    "        XPATH_REVIEW_SECTION_1 = '//div[contains(@id,\"reviews-summary\")]'\n",
    "        XPATH_REVIEW_SECTION_2 = '//div[@data-hook=\"review\"]'\n",
    "        XPATH_AGGREGATE_RATING = '//table[@id=\"histogramTable\"]//tr'\n",
    "        XPATH_PRODUCT_NAME = '//h1//span[@id=\"productTitle\"]//text()'\n",
    "        XPATH_PRODUCT_PRICE = '//span[@id=\"priceblock_ourprice\"]/text()'\n",
    "\n",
    "        raw_product_price = parser.xpath(XPATH_PRODUCT_PRICE)\n",
    "        raw_product_name = parser.xpath(XPATH_PRODUCT_NAME)\n",
    "        total_ratings  = parser.xpath(XPATH_AGGREGATE_RATING)\n",
    "        reviews = parser.xpath(XPATH_REVIEW_SECTION_1)\n",
    "\n",
    "        product_price = ''.join(raw_product_price).replace(',', '')\n",
    "        product_name = ''.join(raw_product_name).strip()\n",
    "\n",
    "        if not reviews:\n",
    "            reviews = parser.xpath(XPATH_REVIEW_SECTION_2)\n",
    "        ratings_dict = {}\n",
    "        reviews_list = []\n",
    "\n",
    "        # Grabing the rating  section in product page\n",
    "        for ratings in total_ratings:\n",
    "            extracted_rating = ratings.xpath('./td//a//text()')\n",
    "            if extracted_rating:\n",
    "                rating_key = extracted_rating[0] \n",
    "                raw_raing_value = extracted_rating[1]\n",
    "                rating_value = raw_raing_value\n",
    "                if rating_key:\n",
    "                    ratings_dict.update({rating_key: rating_value})\n",
    "        \n",
    "        # Parsing individual reviews\n",
    "        for review in reviews:\n",
    "            XPATH_RATING  = './/i[@data-hook=\"review-star-rating\"]//text()'\n",
    "            XPATH_REVIEW_HEADER = './/a[@data-hook=\"review-title\"]//text()'\n",
    "            XPATH_REVIEW_POSTED_DATE = './/span[@data-hook=\"review-date\"]//text()'\n",
    "            XPATH_REVIEW_TEXT_1 = './/div[@data-hook=\"review-collapsed\"]//text()'\n",
    "            XPATH_REVIEW_TEXT_2 = './/div//span[@data-action=\"columnbalancing-showfullreview\"]/@data-columnbalancing-showfullreview'\n",
    "            XPATH_REVIEW_COMMENTS = './/span[@data-hook=\"review-comment\"]//text()'\n",
    "            XPATH_AUTHOR = './/span[contains(@class,\"profile-name\")]//text()'\n",
    "            XPATH_REVIEW_TEXT_3 = './/div[contains(@id,\"dpReviews\")]/div/text()'\n",
    "            \n",
    "            raw_review_author = review.xpath(XPATH_AUTHOR)\n",
    "            raw_review_rating = review.xpath(XPATH_RATING)\n",
    "            raw_review_header = review.xpath(XPATH_REVIEW_HEADER)\n",
    "            raw_review_posted_date = review.xpath(XPATH_REVIEW_POSTED_DATE)\n",
    "            raw_review_text1 = review.xpath(XPATH_REVIEW_TEXT_1)\n",
    "            raw_review_text2 = review.xpath(XPATH_REVIEW_TEXT_2)\n",
    "            raw_review_text3 = review.xpath(XPATH_REVIEW_TEXT_3)\n",
    "\n",
    "            # Cleaning data\n",
    "            author = ' '.join(' '.join(raw_review_author).split())\n",
    "            review_rating = ''.join(raw_review_rating).replace('out of 5 stars', '')\n",
    "            review_header = ' '.join(' '.join(raw_review_header).split())\n",
    "\n",
    "            try:\n",
    "                review_posted_date = dateparser.parse(''.join(raw_review_posted_date)).strftime('%d %b %Y')\n",
    "            except:\n",
    "                review_posted_date = None\n",
    "            review_text = ' '.join(' '.join(raw_review_text1).split())\n",
    "\n",
    "            # Grabbing hidden comments if present\n",
    "            if raw_review_text2:\n",
    "                json_loaded_review_data = loads(raw_review_text2[0])\n",
    "                json_loaded_review_data_text = json_loaded_review_data['rest']\n",
    "                cleaned_json_loaded_review_data_text = re.sub('<.*?>', '', json_loaded_review_data_text)\n",
    "                full_review_text = review_text+cleaned_json_loaded_review_data_text\n",
    "            else:\n",
    "                full_review_text = review_text\n",
    "            if not raw_review_text1:\n",
    "                full_review_text = ' '.join(' '.join(raw_review_text3).split())\n",
    "\n",
    "            raw_review_comments = review.xpath(XPATH_REVIEW_COMMENTS)\n",
    "            review_comments = ''.join(raw_review_comments)\n",
    "            review_comments = sub('[A-Za-z]', '', review_comments).strip()\n",
    "            review_dict = {\n",
    "                                'review_comment_count': review_comments,\n",
    "                                'review_text': full_review_text,\n",
    "                                'review_posted_date': review_posted_date,\n",
    "                                'review_header': review_header,\n",
    "                                'review_rating': review_rating,\n",
    "                                'review_author': author\n",
    "\n",
    "                            }\n",
    "            reviews_list.append(review_dict)\n",
    "\n",
    "        data = {\n",
    "                    'ratings': ratings_dict,\n",
    "                    'reviews': reviews_list,\n",
    "                    'url': amazon_url,\n",
    "                    'name': product_name,\n",
    "                    'price': product_price\n",
    "                \n",
    "                }\n",
    "        return data\n",
    "\n",
    "    return {\"error\": \"failed to process the page\", \"url\": amazon_url}\n",
    "            \n",
    "\n",
    "def ReadAsin():\n",
    "    # Add your own ASINs here\n",
    "    AsinList = ['B01ETPUQ6E', 'B017HW9DEW', 'B00U8KSIOM']\n",
    "    extracted_data = []\n",
    "    \n",
    "    for asin in AsinList:\n",
    "        print(\"Downloading and processing page http://www.amazon.com/dp/\" + asin)\n",
    "        extracted_data.append(ParseReviews(asin))\n",
    "        sleep(5)\n",
    "    f = open('data.json', 'w')\n",
    "    dump(extracted_data, f, indent=4)\n",
    "    f.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ReadAsin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ec5a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
